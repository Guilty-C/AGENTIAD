# Remote Execution Guide: Shared Lab Server Protocol (Zero-Pollution)
# [SECURITY NOTICE]
# NEVER COMMIT SENSITIVE CREDENTIALS (PASSWORD, IP, PRIVATE KEY) TO GIT.
# USE ENVIRONMENT VARIABLES OR LOCAL CONFIGURATION IF NEEDED.
# IF YOU HAVE PREVIOUSLY COMMITTED PASSWORDS, PLEASE ROTATE/REVOKE THEM IMMEDIATELY.

# User: <your_user> (e.g. env: REMOTE_USER)
# Host: <your_host> (e.g. env: REMOTE_HOST)
# Port: 22

This project strictly enforces a "Zero-Pollution" policy for execution on shared lab servers.
Follow this workflow to run code remotely without altering the server environment or leaving artifacts.

## 1. Preparation (Local)
   - Ensure you have SSH access to the lab server (use key-based auth or lab-standard method).
   - Pack the repository excluding 'data' folder and outputs:
     PowerShell: `Compress-Archive -Path ".\src", ".\scripts", ".\dist", ".\configs", ".\*.py", ".\requirements.txt", ".\REMOTE_EXECUTION_GUIDE.txt" -DestinationPath ".\agentiad_repro_tmp.zip" -Force`

## 2. Remote Setup (After git pull / Unzip)
   After pulling or unzipping on the remote Linux server, run the following commands to ensure the environment is ready:

   ```bash
   source conda.sh
   conda activate agentiad
   
   # Check imports
   python3 -c "import yaml"
   python3 -c "import torch, transformers, accelerate, datasets; from PIL import Image"
   
   # If missing dependencies:
   # Option A: Conda (Recommended, using conda-forge)
   conda install -y -c conda-forge transformers accelerate datasets pyarrow pillow
   
   # Option B: Pip (Fallback, may require cmake/build-essential for pyarrow)
   python3 -m pip install transformers accelerate datasets pyarrow pillow
   
   # Run verification
   CUDA_VISIBLE_DEVICES=0 python3 verify_all.py --mode strict_j
   ```

## 3. Execution (Remote via SSH)
   - Upload the zip:
     `scp ".\agentiad_repro_tmp.zip" <user>@<host>:~/`
   
   - Run the "One-Liner" execution block:
     ssh <user>@<host> "bash -lc '
       # A. Create unique temp dir in /tmp
       export TMP_RUN=/tmp/run_\$(date +%s)
       mkdir -p \$TMP_RUN
       
       # B. Unzip
       unzip -q ~/agentiad_repro_tmp.zip -d \$TMP_RUN
       cd \$TMP_RUN
       
       # C. Setup Data (Persistent Cache)
       # Create persistent data dir if not exists (Allowed Exception)
       mkdir -p ~/data/mmad
       # Link it to tmp run
       mkdir -p data
       rm -rf data/mmad
       ln -s ~/data/mmad data/mmad
       
       # D. Download Data (if missing)
       if [ ! -f data/mmad/mmad_manifest.json ]; then
           echo \"Downloading MMAD dataset...\"
           # Add download command here, e.g. python3 scripts/01_get_mmad.py or wget
           python3 scripts/01_get_mmad.py
       fi
       
       # E. Run Verification/Workload
       python3 -m compileall -q verify_all.py
       python3 verify_all.py --mode prep_fullpaper --evidence_dir dist/outputs/evidence_prep_fullpaper
       
       # F. List results to confirm
       ls -lh dist/outputs/evidence_prep_fullpaper/evidence_package.zip
     '"

## 3. Retrieval & Cleanup
   - Download the evidence package:
     `scp <user>@<host>:/tmp/run_*/dist/outputs/evidence_prep_fullpaper/evidence_package.zip ".\dist\outputs\evidence_prep_fullpaper\"`
     `scp <user>@<host>:/tmp/run_*/dist/outputs/evidence_prep_fullpaper/INDEX.txt ".\dist\outputs\evidence_prep_fullpaper\"`

   - Cleanup remote artifacts:
     `ssh <user>@<host> "rm -f ~/agentiad_repro_tmp.zip && rm -rf /tmp/run_*"`

## Key Principles
   - NO git clone on shared servers.
   - NO pip install --user (use virtualenv if needed, but prefer system python if dependencies match).
   - NO artifacts left in home directory (except the transient zip and ~/data/mmad cache).
   - ALWAYS run in /tmp to ensure isolation.
